{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled3.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4QEC-uPrto-9",
        "colab_type": "text"
      },
      "source": [
        "Problem 1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kAmHDWFLttuT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "e0db7cac-dd6f-4408-87e3-dc2726b1b596"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from matplotlib import style\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import random\n",
        "dice=0\n",
        "for i in range(250):\n",
        "    walk = [0] \n",
        "    for x in range(100):\n",
        "        step = walk[-1] \n",
        "        dice = random.randint(1,7)\n",
        "        if dice <= 2 :\n",
        "            step = max(0, step - 1)\n",
        "\n",
        "        elif dice<=5:\n",
        "            step += 1\n",
        "        else:\n",
        "            step = step + random.randint(1,7)\n",
        "    print(step)\n"
      ],
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0\n",
            "0\n",
            "0\n",
            "1\n",
            "0\n",
            "1\n",
            "0\n",
            "2\n",
            "1\n",
            "0\n",
            "1\n",
            "5\n",
            "0\n",
            "0\n",
            "0\n",
            "6\n",
            "1\n",
            "1\n",
            "6\n",
            "2\n",
            "5\n",
            "3\n",
            "0\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "0\n",
            "0\n",
            "6\n",
            "7\n",
            "1\n",
            "1\n",
            "0\n",
            "1\n",
            "7\n",
            "1\n",
            "6\n",
            "1\n",
            "4\n",
            "3\n",
            "1\n",
            "7\n",
            "4\n",
            "1\n",
            "1\n",
            "1\n",
            "6\n",
            "1\n",
            "0\n",
            "3\n",
            "1\n",
            "1\n",
            "2\n",
            "5\n",
            "7\n",
            "1\n",
            "1\n",
            "1\n",
            "3\n",
            "2\n",
            "1\n",
            "0\n",
            "1\n",
            "1\n",
            "0\n",
            "5\n",
            "1\n",
            "6\n",
            "1\n",
            "0\n",
            "1\n",
            "3\n",
            "2\n",
            "0\n",
            "2\n",
            "2\n",
            "0\n",
            "3\n",
            "1\n",
            "1\n",
            "1\n",
            "0\n",
            "0\n",
            "0\n",
            "1\n",
            "0\n",
            "0\n",
            "1\n",
            "1\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "4\n",
            "1\n",
            "1\n",
            "0\n",
            "1\n",
            "4\n",
            "1\n",
            "6\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "0\n",
            "4\n",
            "1\n",
            "1\n",
            "1\n",
            "0\n",
            "1\n",
            "1\n",
            "4\n",
            "1\n",
            "1\n",
            "3\n",
            "0\n",
            "1\n",
            "1\n",
            "1\n",
            "0\n",
            "0\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "0\n",
            "1\n",
            "0\n",
            "0\n",
            "1\n",
            "4\n",
            "0\n",
            "5\n",
            "0\n",
            "1\n",
            "0\n",
            "1\n",
            "0\n",
            "0\n",
            "1\n",
            "0\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "0\n",
            "0\n",
            "1\n",
            "3\n",
            "1\n",
            "2\n",
            "0\n",
            "6\n",
            "0\n",
            "0\n",
            "1\n",
            "1\n",
            "0\n",
            "1\n",
            "1\n",
            "0\n",
            "1\n",
            "1\n",
            "0\n",
            "2\n",
            "1\n",
            "0\n",
            "1\n",
            "0\n",
            "7\n",
            "0\n",
            "5\n",
            "1\n",
            "0\n",
            "0\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "4\n",
            "1\n",
            "4\n",
            "1\n",
            "1\n",
            "7\n",
            "3\n",
            "7\n",
            "0\n",
            "1\n",
            "1\n",
            "0\n",
            "4\n",
            "1\n",
            "5\n",
            "0\n",
            "0\n",
            "7\n",
            "0\n",
            "1\n",
            "0\n",
            "1\n",
            "1\n",
            "7\n",
            "1\n",
            "5\n",
            "0\n",
            "1\n",
            "1\n",
            "1\n",
            "5\n",
            "0\n",
            "0\n",
            "0\n",
            "6\n",
            "6\n",
            "3\n",
            "3\n",
            "1\n",
            "0\n",
            "0\n",
            "0\n",
            "1\n",
            "5\n",
            "1\n",
            "0\n",
            "1\n",
            "1\n",
            "1\n",
            "0\n",
            "1\n",
            "6\n",
            "0\n",
            "0\n",
            "0\n",
            "1\n",
            "7\n",
            "7\n",
            "1\n",
            "1\n",
            "1\n",
            "0\n",
            "6\n",
            "0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Ahv2GVSt3jU",
        "colab_type": "text"
      },
      "source": [
        "Problem 2\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oSPnRXRh4EQ4",
        "colab_type": "text"
      },
      "source": [
        "Random Data Generation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0cAXmr3et-gG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 590
        },
        "outputId": "12e20e00-8593-4046-e5ee-872c3676c336"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import scipy\n",
        "import random\n",
        "from scipy.stats import norm\n",
        "random.seed(1)\n",
        "n= 3\n",
        "X=[]\n",
        "for i in range(0,n):\n",
        "    X_i= scipy.stats.norm.rvs(0, 1, 100)\n",
        "    X.append(X_i)\n",
        "eps=scipy.stats.norm.rvs(0, 1, 100)\n",
        "y = 1 + (0.5 * X[0]) + (0.4 * X[1]) + (0.3 * X[2])  + eps\n",
        "data_ols = {'X0': X[0],'X1':X[1],'X2':X[2] ,'Y': y }\n",
        "df = pd.DataFrame(data_ols)\n",
        "print(df.head())\n",
        "print(df.tail())\n",
        "print(df.info())\n",
        "print(df.describe())"
      ],
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "         X0        X1        X2         Y\n",
            "0  0.310326 -0.538983  0.522009  0.465421\n",
            "1  0.026933  1.005510 -1.519784  1.277331\n",
            "2  1.454472 -1.948507  0.989502  2.918508\n",
            "3  0.299680 -1.090324 -0.968199  0.709074\n",
            "4  1.568637  0.042656 -0.204593  2.866124\n",
            "          X0        X1        X2         Y\n",
            "95 -0.408410  0.615359 -2.553963  1.293379\n",
            "96  1.271942  0.739803  1.451475  0.186336\n",
            "97 -1.462029 -1.407781  0.657375  0.223453\n",
            "98 -0.355275 -1.795455  0.762725 -0.368844\n",
            "99 -0.845194 -0.817530 -1.009229  0.276298\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 100 entries, 0 to 99\n",
            "Data columns (total 4 columns):\n",
            " #   Column  Non-Null Count  Dtype  \n",
            "---  ------  --------------  -----  \n",
            " 0   X0      100 non-null    float64\n",
            " 1   X1      100 non-null    float64\n",
            " 2   X2      100 non-null    float64\n",
            " 3   Y       100 non-null    float64\n",
            "dtypes: float64(4)\n",
            "memory usage: 3.2 KB\n",
            "None\n",
            "               X0          X1          X2           Y\n",
            "count  100.000000  100.000000  100.000000  100.000000\n",
            "mean     0.012668   -0.098384    0.002392    1.004908\n",
            "std      0.984979    1.056384    0.890788    1.207579\n",
            "min     -2.174584   -2.241255   -2.553963   -1.851668\n",
            "25%     -0.761235   -0.900435   -0.565406    0.218403\n",
            "50%     -0.013255   -0.008498   -0.023229    1.016910\n",
            "75%      0.724811    0.740714    0.684799    1.860162\n",
            "max      2.259437    2.192720    2.373255    3.346921\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0MxOY_FouDh_",
        "colab_type": "text"
      },
      "source": [
        "CREATE RANDOM DATA FOR LOGISTIC REGRESSION"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MgMswyknuHC6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "3a4044d3-e667-473c-a7f8-a59023a80367"
      },
      "source": [
        "X = []\n",
        "n = 3\n",
        "for i in range(0,n):\n",
        "  X_i = scipy.stats.norm.rvs(0, 1, 100)\n",
        "  X.append(X_i)\n",
        "odds = (np.exp(1 + (0.5 * X[0]) + (0.4 * X[1]) + (0.3 * X[2])) /(1 + np.exp(1 + (0.5 * X[0]) + (0.4 * X[1]) + (0.3 * X[2]) ))) \n",
        "y1 = [ ]\n",
        "for i in odds:\n",
        "  if (i>=0.5):\n",
        "    y1.append(1)\n",
        "  else:\n",
        "    y1.append(0)\n",
        "data_lr = {'X0': X[0],'X1':X[1],'X2':X[2] ,'Y': y1 }\n",
        "df1 = pd.DataFrame(data_lr)\n",
        "print(df.head())\n",
        "print(df.tail())\n",
        "print(df.info())\n",
        "print(df.describe())\n",
        "\n",
        "\"\"\"CREATE RANDOM DATA FOR k-MEANS CLUSTERING\"\"\"\n",
        "\n",
        "X_a= -2 * np.random.rand(100,2)\n",
        "X_b = 1 + 2 * np.random.rand(50,2)\n",
        "X_a[50:100, :] = X_b\n",
        "plt.scatter(X_a[ : , 0], X_a[ :, 1], s = 50)\n",
        "plt.show()\n",
        "data_kmeans = {'X0': X_a[:,0],'X1':X_a[:,1]}\n",
        "df3 = pd.DataFrame(data_kmeans)\n",
        "print(df.head())\n",
        "print(df.tail())\n",
        "print(df.info())\n",
        "print(df.describe())"
      ],
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "         X0        X1        X2         Y\n",
            "0  0.310326 -0.538983  0.522009  0.465421\n",
            "1  0.026933  1.005510 -1.519784  1.277331\n",
            "2  1.454472 -1.948507  0.989502  2.918508\n",
            "3  0.299680 -1.090324 -0.968199  0.709074\n",
            "4  1.568637  0.042656 -0.204593  2.866124\n",
            "          X0        X1        X2         Y\n",
            "95 -0.408410  0.615359 -2.553963  1.293379\n",
            "96  1.271942  0.739803  1.451475  0.186336\n",
            "97 -1.462029 -1.407781  0.657375  0.223453\n",
            "98 -0.355275 -1.795455  0.762725 -0.368844\n",
            "99 -0.845194 -0.817530 -1.009229  0.276298\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 100 entries, 0 to 99\n",
            "Data columns (total 4 columns):\n",
            " #   Column  Non-Null Count  Dtype  \n",
            "---  ------  --------------  -----  \n",
            " 0   X0      100 non-null    float64\n",
            " 1   X1      100 non-null    float64\n",
            " 2   X2      100 non-null    float64\n",
            " 3   Y       100 non-null    float64\n",
            "dtypes: float64(4)\n",
            "memory usage: 3.2 KB\n",
            "None\n",
            "               X0          X1          X2           Y\n",
            "count  100.000000  100.000000  100.000000  100.000000\n",
            "mean     0.012668   -0.098384    0.002392    1.004908\n",
            "std      0.984979    1.056384    0.890788    1.207579\n",
            "min     -2.174584   -2.241255   -2.553963   -1.851668\n",
            "25%     -0.761235   -0.900435   -0.565406    0.218403\n",
            "50%     -0.013255   -0.008498   -0.023229    1.016910\n",
            "75%      0.724811    0.740714    0.684799    1.860162\n",
            "max      2.259437    2.192720    2.373255    3.346921\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 360x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "         X0        X1        X2         Y\n",
            "0  0.310326 -0.538983  0.522009  0.465421\n",
            "1  0.026933  1.005510 -1.519784  1.277331\n",
            "2  1.454472 -1.948507  0.989502  2.918508\n",
            "3  0.299680 -1.090324 -0.968199  0.709074\n",
            "4  1.568637  0.042656 -0.204593  2.866124\n",
            "          X0        X1        X2         Y\n",
            "95 -0.408410  0.615359 -2.553963  1.293379\n",
            "96  1.271942  0.739803  1.451475  0.186336\n",
            "97 -1.462029 -1.407781  0.657375  0.223453\n",
            "98 -0.355275 -1.795455  0.762725 -0.368844\n",
            "99 -0.845194 -0.817530 -1.009229  0.276298\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 100 entries, 0 to 99\n",
            "Data columns (total 4 columns):\n",
            " #   Column  Non-Null Count  Dtype  \n",
            "---  ------  --------------  -----  \n",
            " 0   X0      100 non-null    float64\n",
            " 1   X1      100 non-null    float64\n",
            " 2   X2      100 non-null    float64\n",
            " 3   Y       100 non-null    float64\n",
            "dtypes: float64(4)\n",
            "memory usage: 3.2 KB\n",
            "None\n",
            "               X0          X1          X2           Y\n",
            "count  100.000000  100.000000  100.000000  100.000000\n",
            "mean     0.012668   -0.098384    0.002392    1.004908\n",
            "std      0.984979    1.056384    0.890788    1.207579\n",
            "min     -2.174584   -2.241255   -2.553963   -1.851668\n",
            "25%     -0.761235   -0.900435   -0.565406    0.218403\n",
            "50%     -0.013255   -0.008498   -0.023229    1.016910\n",
            "75%      0.724811    0.740714    0.684799    1.860162\n",
            "max      2.259437    2.192720    2.373255    3.346921\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DJDbYjZ44pfI",
        "colab_type": "text"
      },
      "source": [
        "Problem 3\n",
        "LINEAR REGRESSION WITH GRADIENT DESCENT"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D0N6u0_AubQL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "10260aff-ebcd-45e9-a31c-460f366c07f4"
      },
      "source": [
        "X = df.iloc[:,0].values\n",
        "#print(X)\n",
        "y = df.iloc[:,3].values\n",
        "b1 = 0\n",
        "b0 = 0\n",
        "l = 0.001\n",
        "epochs = 150\n",
        " \n",
        "n = float(len(X))\n",
        "for i in range(epochs):\n",
        "  y_p = b1*X + b0\n",
        "  loss = np.sum(y_p - y1)**2\n",
        "  d1 = (-2/n) * sum(X * (y - y_p))\n",
        "  d0 = (-2/n) * sum(y - y_p)\n",
        "  b1 = b1 - (l*d1)\n",
        "  b0 = b0 - (l*d0)\n",
        "\n",
        "print(b1,b0)"
      ],
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.1488115293337676 0.2604103480868257\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1DtVN9KkBl6V",
        "colab_type": "text"
      },
      "source": [
        "LOGISTIC REGRESSION WITH GRADIENT DESCENT"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tL_F0YcjukD4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        },
        "outputId": "7c38b812-4fbc-4e42-ece5-1218aa12d786"
      },
      "source": [
        "X1 = df1.iloc[:,0:3].values\n",
        "y1 = df1.iloc[:,3].values\n",
        "\n",
        "def sigmoid(Z):\n",
        "  return 1 /(1+np.exp(-Z))\n",
        "\n",
        "def loss(y1,y_hat):\n",
        "  return -np.mean(y1*np.log(y_hat) + (1-y1)*(np.log(1-y_hat)))\n",
        "\n",
        "W = np.zeros((3,1))\n",
        "b = np.zeros((1,1))\n",
        "\n",
        "m = len(y1)\n",
        "lr = 0.001\n",
        "for epoch in range(1000):\n",
        "  Z = np.matmul(X1,W)+b\n",
        "  A = sigmoid(Z)\n",
        "  logistic_loss = loss(y1,A)\n",
        "  dz = A - y1\n",
        "  dw = 1/m * np.matmul(X1.T,dz)\n",
        "  db = np.sum(dz)\n",
        "  W = W - lr*dw\n",
        "  b = b - lr*db\n",
        "\n",
        "  if epoch % 100 == 0:\n",
        "    print(logistic_loss)"
      ],
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.6931471805599453\n",
            "0.32498661057028644\n",
            "0.32489240809581554\n",
            "0.32480032614489074\n",
            "0.32471032582425724\n",
            "0.32462236883657614\n",
            "0.3245364174588922\n",
            "0.32445243452267714\n",
            "0.32437038339539076\n",
            "0.32429022796349755\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dkdHK2GRuo36",
        "colab_type": "text"
      },
      "source": [
        "LINEAR REGRESSION WITH L1 REGULARIZATION"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DegGooK-utXl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "4f39bff0-cd31-44f9-9880-9584a5b66329"
      },
      "source": [
        "X = df.iloc[:,0].values\n",
        "y = df.iloc[:,3].values\n",
        "b1 = 0\n",
        "b0 = 0\n",
        "l = 0.001\n",
        "epochs = 100\n",
        "lam = 0.1\n",
        " \n",
        "n = float(len(X))\n",
        "for i in range(epochs):\n",
        "  y_p = b1*X + b0\n",
        "  loss = np.sum(y_p - y1)**2 + (lam * b1)\n",
        "  d1 = (-2/n) * sum(X * (y - y_p)) + lam\n",
        "  d0 = (-2/n) * sum(y - y_p)\n",
        "  b1 = b1 - (l*d1)\n",
        "  b0 = b0 - (l*d0)\n",
        "\n",
        "print(b1,b0)"
      ],
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.09489389083272644 0.18220848274203316\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HVMHiGdoB3th",
        "colab_type": "text"
      },
      "source": [
        "LINEAR REGRESSION WITH L2 REGULARIZATION"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W3kFMizfu-7Y",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "7dd1aabe-1d00-40c5-b0a3-5961961ffbe9"
      },
      "source": [
        "X = df.iloc[:,0].values\n",
        "#print(X)\n",
        "y = df.iloc[:,3].values\n",
        "b1 = 0\n",
        "b0 = 0\n",
        "l = 0.001\n",
        "epochs = 100\n",
        "lam = 0.1\n",
        " \n",
        "n = float(len(X))\n",
        "for i in range(epochs):\n",
        "  y_p = b1*X + b0\n",
        "  loss = np.sum(y_p - y1)**2 + ((lam/2) * b1)\n",
        "  d1 = (-2/n) * sum(X * (y - y_p)) + (lam *b1)\n",
        "  d0 = (-2/n) * sum(y - y_p)\n",
        "  b1 = b1 - (l*d1)\n",
        "  b0 = b0 - (l*d0)\n",
        "\n",
        "print(b1,b0)"
      ],
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.10350202313152976 0.18219784445399434\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eSNlmy3QCEA_",
        "colab_type": "text"
      },
      "source": [
        "LOGISTIC REGRESSION WITH L1 REGULARIZATION"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OnneCLqGvWC8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        },
        "outputId": "a786002b-3d65-464b-ee53-4f6765f7e618"
      },
      "source": [
        "X1 = df1.iloc[:,0:3].values\n",
        "y1 = df1.iloc[:,3].values\n",
        "lam = 0.1\n",
        "def sigmoid(Z):\n",
        "  return 1 /(1+np.exp(-Z))\n",
        "\n",
        "def loss(y1,y_hat):\n",
        "  return -np.mean(y1*np.log(y_hat) + (1-y1)*(np.log(1-y_hat))) + (lam * (np.sum(W)))\n",
        "\n",
        "W = np.zeros((3,1))\n",
        "b = np.zeros((1,1))\n",
        "\n",
        "m = len(y1)\n",
        "lr = 0.001\n",
        "for epoch in range(1000):\n",
        "  Z = np.matmul(X1,W)+b\n",
        "  A = sigmoid(Z)\n",
        "  logistic_loss = loss(y1,A)\n",
        "  dz = A - y1\n",
        "  dw = 1/m * np.matmul(X1.T,dz) + lam\n",
        "  db = np.sum(dz)\n",
        "\n",
        "  W = W - lr*dw\n",
        "  b = b - lr*db\n",
        "\n",
        "  if epoch % 100 == 0:\n",
        "    print(logistic_loss)"
      ],
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.6931471805599453\n",
            "0.026930044712504653\n",
            "-0.2684149713498742\n",
            "-0.5606227400836048\n",
            "-0.8497295232990651\n",
            "-1.1357716737877412\n",
            "-1.4187856103285796\n",
            "-1.6988077948189202\n",
            "-1.9758747112341004\n",
            "-2.2500228461294074\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RRcxleuUCNtG",
        "colab_type": "text"
      },
      "source": [
        "LOGISTIC REGRESSION WITH L2 REGULARIZATION"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-fTD3MJLwNKX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        },
        "outputId": "db8a10a6-c4be-4c0f-b1bf-62564928e237"
      },
      "source": [
        "X1 = df1.iloc[:,0:3].values\n",
        "y1 = df1.iloc[:,3].values\n",
        "lam = 0.1\n",
        "def sigmoid(Z):\n",
        "  return 1 /(1+np.exp(-Z))\n",
        "\n",
        "def loss(y1,y_hat):\n",
        "  return -np.mean(y1*np.log(y_hat) + (1-y1)*(np.log(1-y_hat))) + (lam * (np.sum(np.square(W))))\n",
        "\n",
        "W = np.zeros((3,1))\n",
        "b = np.zeros((1,1))\n",
        "\n",
        "m = len(y1)\n",
        "lr = 0.001\n",
        "for epoch in range(1000):\n",
        "  Z = np.matmul(X1,W)+b\n",
        "  A = sigmoid(Z)\n",
        "  logistic_loss = loss(y1,A)\n",
        "  dz = A - y1\n",
        "  dw = 1/m * np.matmul(X1.T,dz) + lam * W\n",
        "  db = np.sum(dz)\n",
        "\n",
        "  W = W - lr*dw\n",
        "  b = b - lr*db\n",
        "\n",
        "  if epoch % 100 == 0:\n",
        "    print(logistic_loss)"
      ],
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.6931471805599453\n",
            "0.32508250821335005\n",
            "0.3252679349692768\n",
            "0.3256275512968807\n",
            "0.3261501894125188\n",
            "0.32682519954145234\n",
            "0.32764242928102827\n",
            "0.32859220377083376\n",
            "0.3296653066285371\n",
            "0.3308529616132199\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-TUBdDtoCUml",
        "colab_type": "text"
      },
      "source": [
        "K-MEANS CLUSTERING ALGORITHM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zteT4DoXCVaq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 320
        },
        "outputId": "9d4e9d2d-e0a4-4605-8280-2bdbdd30a3a4"
      },
      "source": [
        "class K_Means:\n",
        "    def __init__(self, k=2, tol=0.001, max_iter=300):\n",
        "        self.k = k\n",
        "        self.tol = tol\n",
        "        self.max_iter = max_iter\n",
        "\n",
        "    def fit(self,data):\n",
        "\n",
        "        self.centroids = {}\n",
        "\n",
        "        for i in range(self.k):\n",
        "            self.centroids[i] = data[i]\n",
        "\n",
        "        for i in range(self.max_iter):\n",
        "            self.classifications = {}\n",
        "\n",
        "            for i in range(self.k):\n",
        "                self.classifications[i] = []\n",
        "\n",
        "            for featureset in X:\n",
        "                distances = [np.linalg.norm(featureset-self.centroids[centroid]) for centroid in self.centroids]\n",
        "                classification = distances.index(min(distances))\n",
        "                self.classifications[classification].append(featureset)\n",
        "\n",
        "            prev_centroids = dict(self.centroids)\n",
        "\n",
        "            for classification in self.classifications:\n",
        "                self.centroids[classification] = np.average(self.classifications[classification],axis=0)\n",
        "\n",
        "            optimized = True\n",
        "\n",
        "            for c in self.centroids:\n",
        "                original_centroid = prev_centroids[c]\n",
        "                current_centroid = self.centroids[c]\n",
        "                if np.sum((current_centroid-original_centroid)/original_centroid*100.0) > self.tol:\n",
        "                    print(np.sum((current_centroid-original_centroid)/original_centroid*100.0))\n",
        "                    optimized = False\n",
        "\n",
        "            if optimized:\n",
        "                break\n",
        "\n",
        "    def predict(self,data):\n",
        "        distances = [np.linalg.norm(data-self.centroids[centroid]) for centroid in self.centroids]\n",
        "        classification = distances.index(min(distances))\n",
        "        return classification\n",
        "        \n",
        "colors = 10*[\"g\",\"r\",\"c\",\"b\",\"k\"]\n",
        "\n",
        "X = df3.iloc[:,0:2].values\n",
        "clf = K_Means()\n",
        "clf.fit(X)\n",
        "\n",
        "for centroid in clf.centroids:\n",
        "    plt.scatter(clf.centroids[centroid][0], clf.centroids[centroid][1],\n",
        "                marker=\"o\", color=\"k\", s=150, linewidths=5)\n",
        "\n",
        "for classification in clf.classifications:\n",
        "    color = colors[classification]\n",
        "    for featureset in clf.classifications[classification]:\n",
        "        plt.scatter(featureset[0], featureset[1], marker=\"x\", color=color, s=150, linewidths=5)\n",
        "\n",
        "\"\"\"LINEAR REGRESSION WITH OOPS\"\"\"\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "class LinearRegressionModel():\n",
        "\n",
        "    def __init__(self, dataset, learning_rate, num_iterations):\n",
        "        self.dataset = np.array(dataset)\n",
        "        self.b = 0  \n",
        "        self.m = 0  \n",
        "        self.learning_rate = learning_rate\n",
        "        self.num_iterations = num_iterations\n",
        "        self.M = len(self.dataset)\n",
        "        self.total_error = 0\n",
        "\n",
        "    def apply_gradient_descent(self):\n",
        "        for i in range(self.num_iterations):\n",
        "            self.do_gradient_step()\n",
        "\n",
        "    def do_gradient_step(self):\n",
        "        b_summation = 0\n",
        "        m_summation = 0\n",
        "        for i in range(self.M):\n",
        "            x_value = self.dataset[i, 0]\n",
        "            y_value = self.dataset[i, 1]\n",
        "            b_summation += (((self.m * x_value) + self.b) - y_value) \n",
        "            m_summation += (((self.m * x_value) + self.b) - y_value) * x_value\n",
        "        self.b = self.b - (self.learning_rate * (1/self.M) * b_summation)\n",
        "        self.m = self.m - (self.learning_rate * (1/self.M) * m_summation)\n",
        "      \n",
        "    def compute_error(self):\n",
        "        for i in range(self.M):\n",
        "            x_value = self.dataset[i, 0]\n",
        "            y_value = self.dataset[i, 1]\n",
        "            self.total_error += ((self.m * x_value) + self.b) - y_value\n",
        "        return self.total_error\n",
        "\n",
        "    def __str__(self):\n",
        "        return \"Results: b: {}, m: {}, Final Total error: {}\".format(round(self.b, 2), round(self.m, 2), round(self.compute_error(), 2))\n",
        "\n",
        "    def get_prediction_based_on(self, x):\n",
        "        return round(float((self.m * x) + self.b), 2) \n",
        "\n",
        "def main():\n",
        "    school_dataset = np.genfromtxt(DATASET_PATH, delimiter=\",\")\n",
        "    lr = LinearRegressionModel(school_dataset, 0.0001, 1000)\n",
        "    lr.apply_gradient_descent()\n",
        "    hours = [10, 20, 30, 40, 50, 60, 70, 80, 90, 100]\n",
        "    for hour in hours:\n",
        "        print(\"Studied {} hours and got {} points.\".format(hour, lr.get_prediction_based_on(hour)))\n",
        "    print(lr)\n",
        "    if __name__ == \"__main__\": main()"
      ],
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 360x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZhNGfLQnCev3",
        "colab_type": "text"
      },
      "source": [
        "LOGISTIC REGRESSION WITH OOPS"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IiRYROUACfhr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class LogisticRegression:\n",
        "  def __init__(self, learning_rate, num_iters, fit_intercept = True, verbose = False):\n",
        "    self.learning_rate = learning_rate\n",
        "    self.num_iters = num_iters\n",
        "    self.fit_intercept = fit_intercept\n",
        "    self.verbose = verbose\n",
        "  def __add_intercept(self, X):\n",
        "    intercept = np.ones((X.shape[0],1))\n",
        "    return np.concatenate((intercept,X),axis=1)\n",
        "  def __sigmoid(self,z):\n",
        "    return 1/(1+np.exp(-z))\n",
        "  def __loss(self, h, y):\n",
        "    return (-y * np.log(h) - (1-y) * np.log(1-h)).mean()\n",
        "  \n",
        "  def fit(self,X,y):\n",
        "    if self.fit_intercept:\n",
        "      X = self.__add_intercept(X)\n",
        "    self.theta = np.zeros(X.shape[1])\n",
        "    \n",
        "    for i in range(self.num_iters):\n",
        "      z = np.dot(X,self.theta)\n",
        "      h = self.__sigmoid(z)\n",
        "      gradient = np.dot(X.T,(h-y))/y.size\n",
        "      \n",
        "      self.theta -= self.learning_rate * gradient\n",
        "      \n",
        "      z = np.dot(X,self.theta)\n",
        "      h = self.__sigmoid(z)\n",
        "      loss = self.__loss(h,y)\n",
        "      \n",
        "      if self.verbose == True and i % 1000 == 0:\n",
        "        print(f'Loss: {loss}\\t')\n",
        "  def predict_probability(self,X):\n",
        "    if self.fit_intercept:\n",
        "      X = self.__add_intercept(X)\n",
        "    return self.__sigmoid(np.dot(X,self.theta))\n",
        "  def predict(self,X):\n",
        "    return (self.predict_probability(X).round())"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}